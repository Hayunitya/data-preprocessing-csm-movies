# -*- coding: utf-8 -*-
"""518670_Hayunitya Edadwi Pratita_Python Project Data Preprocessing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Afj1wUoapQ5JC-Qfqz5FW6Yms8dHYtr

# **PROJECT DATA PREPROCESSING**

Nama : Hayunitya Edadwi Pratita

NIM : 23/518670/TK/57134

Mata Kuliah : Rekayasa Data

Judul: Preprocessing CSM *(Conventional and Social Media Movies)* Dataset 2014 dan 2015 <br> <br>

## **Daftar Isi**
1. Upload dan Load Data
2. Validasi Nilai
3. Missing Values
4. Feature Engineering
5. Outlier pada Gross dan Budget
6. Cek Redundansi Atribut
7. Keputusan Kolom Sentiment
8. Keputusan PCA
9. Dataset Final
10. Ringkasan dan Insight

<br>

# Step 0. Setup Proyek
Tujuan: Menyiapkan library yang diperlukan dan utilitas kecil agar tampilan rapi.
"""

# Step 0. Setup
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

pd.set_option("display.max_columns", 100)
pd.set_option("display.width", 140)
os.makedirs("figs", exist_ok=True)

def preview(df, n=10, mode="head", title=""):
    if title:
        print(title)
    if mode == "head":
        display(df.head(n))
    elif mode == "tail":
        display(df.tail(n))

"""# Step 1. Upload dan Load Data
Tujuan: Memuat dataset dari file Excel, sheet "Sheet1". Data utama yang digunakan untuk preprocessing ada di Sheet1.
"""

# Step 1. Upload dan load
from google.colab import files
uploaded = files.upload()
FNAME = list(uploaded.keys())[0]

df_raw = pd.read_excel(FNAME, sheet_name="Sheet1")

display(df_raw.dtypes)
preview(df_raw, 10, mode="head", title="Preview df_raw")

"""# Step 2. Validasi Nilai
Tujuan: Memastikan nilai berada pada domain yang benar supaya analisis tidak bias.

Aturan yang diterapkan:
1. Year hanya 2014 atau 2015 untuk menjaga ruang lingkup dataset.
2. Ratings dalam rentang 0 sampai 10. Nilai di luar rentang dianggap tidak valid lalu diubah menjadi NaN agar dapat diimputasi.
3. Semua kolom numerik tidak boleh bernilai negatif. Nilai negatif diubah menjadi NaN.
4. Duplikasi berdasarkan Movie dan Year dihapus untuk menghindari hitungan ganda.
"""

# Step 2. Validasi nilai
df = df_raw.copy()

# Tahun
if "Year" in df.columns:
    df = df[df["Year"].isin([2014, 2015])].copy()

# Ratings dalam rentang 0 sampai 10. Di luar rentang dibuat NaN agar terlihat pada tahap missing
if "Ratings" in df.columns:
    df.loc[(df["Ratings"] < 0) | (df["Ratings"] > 10), "Ratings"] = np.nan

# Semua kolom numerik tidak boleh negatif
for c in df.select_dtypes(include=[np.number]).columns:
    df.loc[df[c] < 0, c] = np.nan

# Hapus duplikasi Movie + Year
before = len(df)
if {"Movie","Year"}.issubset(df.columns):
    df = df.drop_duplicates(subset=["Movie","Year"])

print("Duplikasi dibuang:", before - len(df))
print("Shape setelah validasi:", df.shape)

# Preview setelah validasi
preview(df, 10, mode="head", title="Preview setelah validasi")

"""# Step 3. Missing Values
Tujuan: Membersihkan nilai kosong secara aman agar analisis tidak bias.

Kebijakan yang digunakan:
1. Gross dan Budget wajib ada. Baris kosong pada dua kolom ini dihapus.
2. Nol pada Budget dan Views diperlakukan NaN agar aman dari pembagian nol.
3. Kolom numerik lain diimputasi median per Year.
"""

# Step 3. Missing values

# Ganti nol berisiko menjadi NaN agar tidak membagi nol
for col in ["Budget", "Views"]:
    if col in df.columns:
        df.loc[df[col] == 0, col] = np.nan

print("Missing sebelum:")
display(df.isna().sum())

# Baris wajib: Gross dan Budget harus ada
must_have = [c for c in ["Gross","Budget"] if c in df.columns]
if must_have:
    before = len(df)
    df = df.dropna(subset=must_have).copy()
    print("Baris dibuang karena Gross atau Budget NaN:", before - len(df))

# Imputasi median per Year untuk kolom numerik lain
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
for c in num_cols:
    if c in must_have:  # sudah ditangani
        continue
    if "Year" in df.columns:
        df[c] = df.groupby("Year")[c].transform(lambda s: s.fillna(s.median()))
    else:
        df[c] = df[c].fillna(df[c].median())

print("Missing sesudah:")
display(df.isna().sum())
print("Shape:", df.shape)
preview(df, 10, mode="head", title="Preview setelah missing handling")

"""# Step 4. Feature Engineering
Tujuan: Membuat kolom yang lebih informatif tanpa menambah kompleksitas.

Kolom yang ditambahkan:
1. ROI = Gross per Budget. Mengukur efektivitas biaya.
2. EngagementRate = (Likes + Comments) per Views. Mengukur kualitas interaksi sosial. Semua perhitungan dijaga agar tidak terjadi pembagian nol.

Hasil yang diharapkan: Kolom ROI dan EngagementRate muncul.
"""

# Step 4. Feature engineering
if {"Gross","Budget"}.issubset(df.columns):
    df["ROI"] = np.where(df["Budget"] > 0, df["Gross"] / df["Budget"], np.nan)

if {"Likes","Comments","Views"}.issubset(df.columns):
    denom = df["Views"].replace(0, np.nan)
    df["EngagementRate"] = (df["Likes"] + df["Comments"]) / denom

preview(df[["Movie","Year","Gross","Budget","ROI", "Views","Likes","Comments", "EngagementRate"]].dropna().head(10) if "Movie" in df.columns else df.head(10), 10, title="Preview kolom turunan")

"""# Step 5. Outlier pada Gross dan Budget
Tujuan: Mengendalikan pengaruh nilai ekstrem agar ringkasan dan grafik tidak bias.

Metode yang digunakan: Winsorizing berbasis IQR.
1. Batas bawah = Q1 − k×IQR.
2. Batas atas = Q3 + k×IQR.
3. Nilai di luar batas di-cap ke batas.
4. Tidak ada baris yang dihapus.
5. ROI dihitung ulang.
6. Parameter. k = 1.5.

Hasil: Tabel ringkasan batas, jumlah nilai yang di-cap, dan grafik sebelum vs sesudah.
"""

# Step 5. Outlier, winsorize Gross dan Budget

# Simpan salinan sebelum koreksi untuk perbandingan
df_before_outlier = df.copy()

# Kolom target dan parameter
FIX_OUTLIER_COLS = ["Gross","Budget"]
WINSOR_K = 1.5
BINS_HIST = 40

# Fungsi IQR dan batas
def iqr_stats(s, k=1.5):
    s = pd.to_numeric(s, errors="coerce").dropna()
    q1 = s.quantile(0.25)
    q3 = s.quantile(0.75)
    iqr = q3 - q1
    return q1, q3, iqr, q1 - k*iqr, q3 + k*iqr

# Winsorize setiap kolom target
fix_cols = [c for c in FIX_OUTLIER_COLS if c in df.columns]
recap, bounds = [], []

for c in fix_cols:
    q1, q3, iqr, low, high = iqr_stats(df[c], k=WINSOR_K)
    bounds.append({"column": c, "Q1": q1, "Q3": q3, "IQR": iqr, "lower": low, "upper": high})

    before = pd.to_numeric(df[c], errors="coerce")
    df[c] = before.clip(lower=low, upper=high)
    recap.append({
        "column": c,
        "low_capped": int((before < low).sum()),
        "high_capped": int((before > high).sum())
    })

print("Ringkasan winsorizing:")
display(pd.DataFrame(recap).set_index("column"))
print("Batas IQR:")
display(pd.DataFrame(bounds).set_index("column").round(3))

# Hitung ulang ROI agar konsisten
if {"Gross","Budget"}.issubset(df.columns):
    df["ROI"] = np.where(df["Budget"] > 0, df["Gross"] / df["Budget"], np.nan)

# Visual
for c in fix_cols:
    q1, q3, iqr, low, high = iqr_stats(df_before_outlier[c], k=WINSOR_K)

    plt.figure()
    plt.hist(df_before_outlier[c].dropna(), bins=BINS_HIST, histtype="step", label="sebelum")
    plt.hist(df[c].dropna(),             bins=BINS_HIST, histtype="step", label="sesudah")
    plt.axvline(low,  linestyle="--", label="batas bawah")
    plt.axvline(high, linestyle="--", label="batas atas")
    plt.title(f"Distribusi {c}. sebelum vs sesudah winsorize")
    plt.legend(); plt.tight_layout()
    plt.savefig(f"figs/hist_{c}_before_after.png", dpi=150)
    plt.show()

    plt.figure()
    plt.boxplot([df_before_outlier[c].dropna(), df[c].dropna()], labels=["sebelum","sesudah"], showfliers=True)
    plt.title(f"Box plot {c}. sebelum vs sesudah")
    plt.tight_layout()
    plt.savefig(f"figs/box_{c}_before_after.png", dpi=150)
    plt.show()

# Preview ringkas setelah outlier
print("Preview setelah outlier:")
cols_show = [c for c in ["Movie","Year","Gross","Budget","ROI"] if c in df.columns]
if cols_show:
  display(df[cols_show].head(10))

"""# Step 6. Cek Redundansi Atribut
Tujuan: Menilai apakah ada atribut yang sangat berkorelasi sehingga berpotensi redundant.

Metode yang digunakan: Matriks korelasi untuk Views, Likes, Dislikes, Comments, Aggregate Followers.
"""

# Step 6. Cek redundansi
social_cols = [c for c in ["Views","Likes","Dislikes","Comments","Aggregate Followers"] if c in df.columns]
if len(social_cols) >= 2:
    corr = df[social_cols].corr(method="pearson").abs()
    print("Korelasi antar metrik sosial:")
    display(corr)

    pairs = []
    for i, a in enumerate(social_cols):
        for b in social_cols[i+1:]:
            pairs.append((a, b, corr.loc[a, b]))
    pairs = sorted(pairs, key=lambda x: x[2], reverse=True)
    print("Pasangan korelasi:")
    for a, b, v in pairs[:20]:
        print(f"{a} vs {b}: {v:.3f}")
else:
    print("Metrik sosial tidak lengkap. Lewati cek redundansi.")

"""# Step 7. Keputusan Kolom Sentiment
Tujuan: Menentukan apakah kolom Sentiment dipertahankan.

Alasan: Sentiment pada dataset ini banyak yang bernilai 0.

Kriteria hapus: Proporsi 0 ≥ 0.90 atau varians sangat rendah, dan korelasi absolut dengan Gross serta ROI < 0.05.


"""

# Step 7. Keputusan kolom Sentiment
import numpy as np
import pandas as pd

if "Sentiment" in df.columns:
    s = pd.to_numeric(df["Sentiment"], errors="coerce")
    zero_ratio = (s == 0).mean() if len(s) else np.nan
    nunique = s.nunique(dropna=True)
    var = float(s.var()) if s.notna().any() else np.nan

    corr_gross = df["Gross"].corr(s) if {"Gross"}.issubset(df.columns) else np.nan
    corr_roi   = df["ROI"].corr(s)   if {"ROI"}.issubset(df.columns)   else np.nan

    print("Sentiment check")
    print(f"- proporsi 0: {zero_ratio:.3f}")
    print(f"- unique values: {nunique}")
    print(f"- variance: {var:.3f}" if not np.isnan(var) else "- variance: NaN")
    print(f"- corr(Sentiment, Gross): {corr_gross:.3f}" if not np.isnan(corr_gross) else "- corr dengan Gross: NaN")
    print(f"- corr(Sentiment, ROI)  : {corr_roi:.3f}"   if not np.isnan(corr_roi)   else "- corr dengan ROI  : NaN")

    VERY_MANY_ZEROS = zero_ratio >= 0.90
    VERY_LOW_VAR    = (not np.isnan(var)) and var < 1e-6
    WEAK_CORR       = (np.isnan(corr_gross) or abs(corr_gross) < 0.05) and (np.isnan(corr_roi) or abs(corr_roi) < 0.05)

    DROP_SENTIMENT = (VERY_MANY_ZEROS or VERY_LOW_VAR) and WEAK_CORR

    if DROP_SENTIMENT:
        df.drop(columns=["Sentiment"], inplace=True)
        print("Keputusan. Sentiment DIHAPUS karena hampir semua 0 atau varians sangat rendah dan korelasi lemah.")
    else:
        print("Keputusan. Sentiment DIPERTAHANKAN karena masih ada variasi atau korelasi yang berguna.")
else:
    print("Kolom Sentiment tidak ada. Lewati.")

"""# Step 8. Keputusan PCA
Tujuan: Memutuskan apakah PCA dibutuhkan untuk reduksi dimensi.

Kriteria sederhana: Jika korelasi maksimum antar metrik sosial sangat tinggi, PCA dipertimbangkan. Jika tidak, PCA tidak perlu.
"""

# Step 8. Keputusan PCA
NEED_PCA = False
if len(social_cols) >= 2:
    max_corr = df[social_cols].corr().abs().where(~np.eye(len(social_cols), dtype=bool)).max().max()
    print(f"Maks korelasi absolut antar metrik sosial: {max_corr:.3f}")
    NEED_PCA = bool(max_corr >= 0.92)
else:
    print("Cek PCA dilewati. Metrik sosial tidak lengkap.")

print("Keputusan PCA:", "Perlu" if NEED_PCA else "Tidak perlu")

"""# Step 9. Dataset Final
Tujuan: Menyimpan hasil preprocessing untuk analisis dan visual.
"""

# Step 9. Dataset final
cols_keep = [c for c in [
    "Movie","Year","Ratings","Genre","Gross","Budget","Screens","Sequel",
    "Sentiment","Views","Likes","Dislikes","Comments","Aggregate Followers",
    "ROI","EngagementRate","PC1","PC2","PC3"
] if c in df.columns]

df_final = df[cols_keep].copy()
df_final.to_csv("csm_final_minimal.csv", index=False)
print("Saved csm_final_minimal.csv. Shape:", df_final.shape)
preview(df_final, 10)

# Heatmap korelasi akhir
num_cols_final = df_final.select_dtypes(include=[np.number]).columns
if len(num_cols_final) >= 2:
    corr = df_final[num_cols_final].corr()
    plt.figure(figsize=(6, 5))
    plt.imshow(corr, cmap="coolwarm", vmin=-1, vmax=1)
    plt.colorbar()
    plt.xticks(range(len(num_cols_final)), num_cols_final, rotation=90)
    plt.yticks(range(len(num_cols_final)), num_cols_final)
    plt.title("Heatmap Korelasi")
    plt.tight_layout()
    plt.savefig("figs/corr_final.png", dpi=150)
    plt.show()

# Histogram ROI dan EngagementRate
for col in ["ROI", "EngagementRate"]:
    if col in df_final.columns:
        plt.figure()
        plt.hist(df_final[col].dropna(), bins=30)
        plt.title(f"Distribusi {col}")
        plt.tight_layout()
        plt.savefig(f"figs/hist_{col}.png", dpi=150)
        plt.show()

"""# Step 10. Ringkasan dan Insight
Tujuan: Memberi angka ringkas dan hubungan sederhana setelah preprocessing.
"""

# Step 10. Ringkasan dan insight singkat

# Ringkasan per tahun
cols_summary = [c for c in ["Gross","Budget","ROI","EngagementRate"] if c in df.columns]
if "Year" in df.columns and cols_summary:
    agg = df.groupby("Year")[cols_summary].agg(["median","mean","std"])
    print("Ringkasan per tahun. median, mean, std:")
    display(agg.round(3))

# Top 10 ROI per tahun
if {"Movie","Year","ROI"}.issubset(df.columns):
    top_roi = (
        df.dropna(subset=["ROI"])
          .sort_values(["Year","ROI"], ascending=[True, False])
          .groupby("Year")
          .head(10)[["Year","Movie","ROI","Gross","Budget"]]
    )
    print("Top 10 ROI per tahun:")
    display(top_roi.reset_index(drop=True))

# Korelasi sederhana untuk hubungan sosial vs performa
pairs = []
targets_left  = [c for c in ["Views","Likes","Comments","Aggregate Followers"] if c in df.columns]
targets_right = [c for c in ["Gross","ROI"] if c in df.columns]
for a in targets_left:
    for b in targets_right:
        r = df[a].corr(df[b])
        pairs.append((a, b, r))
if pairs:
    corr_tbl = pd.DataFrame(pairs, columns=["feature","target","pearson_r"]).sort_values("pearson_r", ascending=False)
    print("Korelasi kolom sosial terhadap target:")
    display(corr_tbl.round(3))

# Scatter Gross vs Budget dan ROI vs Ratings
print("Scatter Gross vs Budget:")
if {"Gross","Budget"}.issubset(df.columns):
    plt.figure()
    plt.scatter(df["Budget"], df["Gross"], alpha=0.6)
    plt.xlabel("Budget"); plt.ylabel("Gross"); plt.title("Scatter Budget vs Gross")
    plt.tight_layout(); plt.savefig("figs/scatter_budget_gross.png", dpi=150); plt.show()

print("ROI vs Ratings:")
if {"Ratings","ROI"}.issubset(df.columns):
    plt.figure()
    plt.scatter(df["Ratings"], df["ROI"], alpha=0.6)
    plt.xlabel("Ratings"); plt.ylabel("ROI"); plt.title("Scatter Ratings vs ROI")
    plt.tight_layout(); plt.savefig("figs/scatter_ratings_roi.png", dpi=150); plt.show()